# ğŸ¥ Medical SFT â€” TÃ¼rkÃ§e TÄ±bbi Dil Modeli Fine-Tuning

TÃ¼rkÃ§e tÄ±bbi sorulara doÄŸru ve kapsamlÄ± yanÄ±tlar Ã¼retebilen dil modelleri oluÅŸturmak iÃ§in **Supervised Fine-Tuning (SFT)** pipeline'Ä±.

## ğŸ“‹ Proje HakkÄ±nda

Bu proje, aÃ§Ä±k kaynaklÄ± LLM'leri (Llama 3.2, Qwen3 vb.) TÃ¼rkÃ§e tÄ±bbi veri seti Ã¼zerinde fine-tune ederek, tÄ±p alanÄ±nda uzmanlaÅŸmÄ±ÅŸ asistanlar oluÅŸturmayÄ± amaÃ§lar. EÄŸitim sÃ¼reci **LoRA/QLoRA** ile parametre verimli ÅŸekilde gerÃ§ekleÅŸtirilir ve dÃ¼ÅŸÃ¼k VRAM'li GPU'larda (4GB+) Ã§alÄ±ÅŸabilir.

### âœ¨ Ã–zellikler

- ğŸš€ **Unsloth** ile 2x hÄ±zlÄ± fine-tuning ve %60+ VRAM tasarrufu
- ğŸ§¬ **QLoRA** â€” 4-bit quantization ile dÃ¼ÅŸÃ¼k GPU bellek kullanÄ±mÄ±
- ğŸ“Š **Otomatik metrik hesaplama** â€” BLEU, ROUGE, BERTScore
- ğŸ“¦ **Tek komutla HF Hub'a yÃ¼kleme** â€” Model kartÄ± otomatik oluÅŸturulur
- ğŸ‡¹ğŸ‡· **TÃ¼rkÃ§e tÄ±bbi veri seti** â€” 47K+ soru-cevap Ã§ifti

---

## ğŸ¤— YayÄ±nlanan Model

<a href="https://huggingface.co/emrullahcelik/Llama-3.2-1B-Instruct-Medical-SFT">
  <img src="https://img.shields.io/badge/ğŸ¤—%20Hugging%20Face-Llama--3.2--1B--Medical--SFT-blue?style=for-the-badge" alt="Hugging Face Model"/>
</a>

**[emrullahcelik/Llama-3.2-1B-Instruct-Medical-SFT](https://huggingface.co/emrullahcelik/Llama-3.2-1B-Instruct-Medical-SFT)** â€” Bu pipeline ile eÄŸitilmiÅŸ ve HF Hub'a yÃ¼klenmiÅŸ model.

```python
from transformers import AutoTokenizer, AutoModelForCausalLM

model_id = "emrullahcelik/Llama-3.2-1B-Instruct-Medical-SFT"
tokenizer = AutoTokenizer.from_pretrained(model_id)
model = AutoModelForCausalLM.from_pretrained(model_id, torch_dtype="auto", device_map="auto")

messages = [
    {"role": "system", "content": "Sen tÄ±p alanÄ±nda uzmanlaÅŸmÄ±ÅŸ, TÃ¼rkÃ§e yanÄ±t veren bir yapay zeka asistanÄ±sÄ±n."},
    {"role": "user", "content": "Hipertansiyon nedir ve tedavisi nasÄ±l yapÄ±lÄ±r?"}
]

text = tokenizer.apply_chat_template(messages, tokenize=False, add_generation_prompt=True)
inputs = tokenizer([text], return_tensors="pt").to(model.device)

outputs = model.generate(**inputs, max_new_tokens=256, temperature=0.1, top_p=0.9)
response = tokenizer.decode(outputs[0][len(inputs.input_ids[0]):], skip_special_tokens=True)
print(response)
```

## ğŸ—‚ï¸ Proje YapÄ±sÄ±

```
qwen-sft-medical/
â”œâ”€â”€ app/
â”‚   â”œâ”€â”€ .env                     # HF_TOKEN, HF_USERNAME
â”‚   â”œâ”€â”€ config.py                # Proje ayarlarÄ± ve dizin yollarÄ±
â”‚   â”œâ”€â”€ core/
â”‚   â”‚   â””â”€â”€ logger.py            # Loguru tabanlÄ± loglama
â”‚   â”œâ”€â”€ unsloth-sft/             # ğŸ”¥ Unsloth ile SFT pipeline
â”‚   â”‚   â”œâ”€â”€ train.py             # Model eÄŸitimi
â”‚   â”‚   â”œâ”€â”€ inference.py         # Ã‡Ä±karÄ±m & demo
â”‚   â”‚   â”œâ”€â”€ test.py              # Metrik deÄŸerlendirme
â”‚   â”‚   â”œâ”€â”€ publish.py           # HF Hub'a yÃ¼kleme
â”‚   â”‚   â””â”€â”€ metrics/             # Test sonuÃ§larÄ±
â”‚   â”‚       â”œâ”€â”€ results.json
â”‚   â”‚       â””â”€â”€ scores.png
â”‚   â””â”€â”€ models/
â”‚       â”œâ”€â”€ pre-trained/         # Ä°ndirilen base modeller (cache)
â”‚       â”œâ”€â”€ checkpoints/         # EÄŸitim sÄ±rasÄ±ndaki checkpointler
â”‚       â””â”€â”€ finetuned/           # Son fine-tuned model & adapter
â”œâ”€â”€ .gitignore
â””â”€â”€ README.md
```

---

## ğŸš€ HÄ±zlÄ± BaÅŸlangÄ±Ã§

### 1. OrtamÄ± HazÄ±rla

```bash
# Virtual environment oluÅŸtur
python3 -m venv .venv
source .venv/bin/activate

# PyTorch (CUDA 12.4+)
pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu124

# BaÄŸÄ±mlÄ±lÄ±klar
pip install unsloth transformers trl datasets loguru python-dotenv tensorboard
pip install evaluate nltk matplotlib rouge-score bert-score  # Test iÃ§in
```

### 2. `.env` DosyasÄ±nÄ± Ayarla

```bash
# app/.env
HF_TOKEN=hf_xxxxxxxxxxxxxxxxxxxxx
HF_USERNAME=kullanici_adi
```

### 3. EÄŸitimi BaÅŸlat

```bash
python -m app.unsloth-sft.train
```

### 4. Modeli Test Et

```bash
# HÄ±zlÄ± Ã§Ä±karÄ±m (3 Ã¶rnek soru)
python -m app.unsloth-sft.inference

# Metrik deÄŸerlendirme (BLEU, ROUGE, BERTScore)
python -m app.unsloth-sft.test
```

### 5. HF Hub'a YÃ¼kle

```bash
python -m app.unsloth-sft.publish
```

---

## ğŸ§¬ EÄŸitim DetaylarÄ±

### Model & Veri Seti

| Parametre | DeÄŸer |
|-----------|-------|
| **Base Model** | [unsloth/Llama-3.2-1B-Instruct](https://huggingface.co/unsloth/Llama-3.2-1B-Instruct) |
| **Veri Seti** | [turkerberkdonmez/TUSGPT-TR-Medical-Dataset-v1](https://huggingface.co/datasets/turkerberkdonmez/TUSGPT-TR-Medical-Dataset-v1) |
| **Veri Boyutu** | 47,169 train / 4,148 val / 4,148 test |
| **Chat Template** | Llama 3.1 |

### LoRA KonfigÃ¼rasyonu

| Parametre | DeÄŸer |
|-----------|-------|
| Rank (r) | 16 |
| Alpha | 32 |
| Dropout | 0 |
| Target Modules | q_proj, k_proj, v_proj, o_proj, gate_proj, up_proj, down_proj |
| Trainable Parameters | 11.27M / 1.25B (%0.90) |

### EÄŸitim Hiperparametreleri

| Parametre | DeÄŸer |
|-----------|-------|
| Epochs | 1 |
| Batch Size | 2 |
| Gradient Accumulation | 4 (effective: 8) |
| Learning Rate | 2e-4 |
| LR Scheduler | Linear |
| Optimizer | AdamW 8-bit |
| Precision | BFloat16 |
| Quantization | 4-bit (QLoRA) |
| Max Seq Length | 1024 |
| Packing | âœ… (5x hÄ±zlandÄ±rma) |
| Gradient Checkpointing | Unsloth optimized |
| Train Strategy | `train_on_responses_only` |

### EÄŸitim SonuÃ§larÄ±

| Metrik | DeÄŸer |
|--------|-------|
| **BaÅŸlangÄ±Ã§ Loss** | 3.14 |
| **Son Loss** | ~1.57 |
| **Loss Azalma** | ~%50 |
| **EÄŸitim SÃ¼resi** | ~6 saat |
| **GPU** | NVIDIA RTX 3050 Ti (4GB) |
| **Peak VRAM** | 2.88 GB (%72) |

---

## ğŸ“Š DeÄŸerlendirme

Test scripti (`test.py`) aÅŸaÄŸÄ±daki metrikleri hesaplar:

- **BLEU** â€” N-gram Ã¶rtÃ¼ÅŸme skoru
- **ROUGE-1 / ROUGE-2 / ROUGE-L** â€” Recall-oriented metin benzerliÄŸi
- **BERTScore** â€” Anlamsal benzerlik (precision, recall, F1)

SonuÃ§lar `app/unsloth-sft/metrics/` altÄ±nda JSON ve grafik olarak kaydedilir.

---

## ğŸ› ï¸ Komut ReferansÄ±

| Komut | AÃ§Ä±klama |
|-------|----------|
| `python -m app.unsloth-sft.train` | Modeli eÄŸit |
| `python -m app.unsloth-sft.inference` | 3 Ã¶rnek tÄ±bbi soruyla test et |
| `python -m app.unsloth-sft.test` | BLEU/ROUGE/BERTScore hesapla |
| `python -m app.unsloth-sft.publish` | HF Hub'a merge & yÃ¼kle |

---

## ğŸ“ Sistem Gereksinimleri

- **GPU:** NVIDIA GPU (4GB+ VRAM), CUDA 8.6+
- **Python:** 3.10+
- **OS:** Linux (WSL2 desteklenir)
- **Disk:** ~10GB (model cache + checkpoints)

---

## âš ï¸ Sorumluluk Reddi

Bu proje yalnÄ±zca **araÅŸtÄ±rma ve eÄŸitim** amaÃ§lÄ±dÄ±r. Ãœretilen modeller **tÄ±bbi teÅŸhis veya tedavi iÃ§in kullanÄ±lmamalÄ±dÄ±r**. SaÄŸlÄ±k sorunlarÄ±nÄ±z iÃ§in mutlaka bir saÄŸlÄ±k profesyoneline danÄ±ÅŸÄ±n.

---

## ğŸ“„ Lisans

- **Model:** Llama 3.2 Community License
- **Veri Seti:** Veri seti lisansÄ±na tabidir

---

<p align="center">
  <i>Unsloth ğŸ¦¥ ile hÄ±zlandÄ±rÄ±lmÄ±ÅŸ fine-tuning</i>
</p>